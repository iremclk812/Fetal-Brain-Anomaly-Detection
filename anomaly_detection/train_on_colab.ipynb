{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d4f813",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Mount Google Drive & Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c37a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe356aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install open_clip_torch pytorch-lightning albumentations grad-cam seaborn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a8965",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Project Files\n",
    "\n",
    "**≈ûu dosyalarƒ± Google Drive'a y√ºkleyin:**\n",
    "1. `FetalCLIP_config.json`\n",
    "2. `FetalCLIP_weights.pt`\n",
    "3. `preprocessed_data/` klas√∂r√ºn√º zip'leyin ‚Üí `preprocessed_data.zip`\n",
    "\n",
    "**Drive'da ≈üu yapƒ±yƒ± olu≈üturun:**\n",
    "```\n",
    "My Drive/\n",
    "  FetalBrain/\n",
    "    FetalCLIP_config.json\n",
    "    FetalCLIP_weights.pt\n",
    "    preprocessed_data.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract preprocessed data\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Drive paths (deƒüi≈ütirin gerekirse)\n",
    "DRIVE_DIR = '/content/drive/MyDrive/FetalBrain'\n",
    "WORK_DIR = '/content/fetal_brain'\n",
    "\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# Extract preprocessed data\n",
    "print(\"Extracting preprocessed_data.zip...\")\n",
    "with zipfile.ZipFile(f'{DRIVE_DIR}/preprocessed_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(WORK_DIR)\n",
    "\n",
    "print(\"‚úì Data extracted!\")\n",
    "!ls -lh {WORK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615bb46e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import open_clip\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths\n",
    "PATH_FETALCLIP_CONFIG = f'{DRIVE_DIR}/FetalCLIP_config.json'\n",
    "PATH_FETALCLIP_WEIGHT = f'{DRIVE_DIR}/FetalCLIP_weights.pt'\n",
    "PREPROCESSED_DIR = f'{WORK_DIR}/preprocessed_data'\n",
    "OUTPUT_DIR = f'{WORK_DIR}/results'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Config - BINARY CLASSIFICATION\n",
    "CLASS_NAMES = ['Trans-thalamic', 'Other']\n",
    "NUM_CLASSES = 2\n",
    "DICT_CLSNAME_TO_CLSINDEX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "\n",
    "BATCH_SIZE = 32  # Colab GPU i√ßin optimize\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DENSE_UNITS = 512\n",
    "DROPOUT_RATE = 0.5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"\\nüéØ Binary Plane Classification (Gatekeeper Model)\")\n",
    "print(f\"   - Trans-thalamic (0): Valid for HC measurement\")\n",
    "print(f\"   - Other (1): Invalid planes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb0d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class FetalBrainDataset(Dataset):\n",
    "    def __init__(self, preprocessed_dir, split='train', transform=None):\n",
    "        self.preprocessed_dir = os.path.join(preprocessed_dir, split)\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        for filename in os.listdir(self.preprocessed_dir):\n",
    "            if not filename.endswith('.png'):\n",
    "                continue\n",
    "            \n",
    "            class_name = None\n",
    "            for cn in CLASS_NAMES:\n",
    "                if cn in filename:\n",
    "                    class_name = cn\n",
    "                    break\n",
    "            \n",
    "            if class_name is not None:\n",
    "                self.data.append({\n",
    "                    'path': os.path.join(self.preprocessed_dir, filename),\n",
    "                    'label': DICT_CLSNAME_TO_CLSINDEX[class_name],\n",
    "                    'class_name': class_name\n",
    "                })\n",
    "        \n",
    "        print(f\"  {split.upper()}: {len(self.data)} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image = Image.open(item['path']).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, item['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af09e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FetalCLIP\n",
    "print(\"\\nüì¶ Loading FetalCLIP...\")\n",
    "with open(PATH_FETALCLIP_CONFIG, \"r\") as file:\n",
    "    config_fetalclip = json.load(file)\n",
    "open_clip.factory._MODEL_CONFIGS[\"FetalCLIP\"] = config_fetalclip\n",
    "\n",
    "model_fetalclip, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    \"FetalCLIP\", \n",
    "    pretrained=PATH_FETALCLIP_WEIGHT\n",
    ")\n",
    "model_fetalclip = model_fetalclip.to(device)\n",
    "model_fetalclip.eval()\n",
    "\n",
    "# Freeze FetalCLIP\n",
    "for param in model_fetalclip.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"‚úì FetalCLIP loaded and frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6521f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Classifier - BINARY OUTPUT\n",
    "class FetalBrainClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=768, dense_units=512, num_classes=2, dropout_rate=0.5):\n",
    "        super(FetalBrainClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(embedding_dim, dense_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(dense_units, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "classifier = FetalBrainClassifier(\n",
    "    embedding_dim=768,\n",
    "    dense_units=DENSE_UNITS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nüß† Binary Classifier: {sum(p.numel() for p in classifier.parameters()):,} parameters\")\n",
    "print(f\"   Architecture: FetalCLIP ‚Üí Linear(768‚Üí512) ‚Üí ReLU ‚Üí Dropout(0.5) ‚Üí Linear(512‚Üí2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "print(\"\\nüìä Loading datasets...\")\n",
    "train_dataset = FetalBrainDataset(PREPROCESSED_DIR, 'train', preprocess)\n",
    "val_dataset = FetalBrainDataset(PREPROCESSED_DIR, 'val', preprocess)\n",
    "test_dataset = FetalBrainDataset(PREPROCESSED_DIR, 'test', preprocess)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\n‚úì Batches: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bde901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "}\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "EARLY_STOP_PATIENCE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204d9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nüìç Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    # TRAIN\n",
    "    classifier.train()\n",
    "    train_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Extract embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = model_fetalclip.encode_image(images)\n",
    "            embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = classifier(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = np.mean(np.array(train_preds) == np.array(train_labels))\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
    "    \n",
    "    # VALIDATION\n",
    "    classifier.eval()\n",
    "    val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            embeddings = model_fetalclip.encode_image(images)\n",
    "            embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            outputs = classifier(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(classifier.state_dict(), f'{OUTPUT_DIR}/best_classifier.pt')\n",
    "        print(f\"  ‚ú® New best model saved! (F1: {best_val_f1:.4f})\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  ‚è≥ Patience: {patience_counter}/{EARLY_STOP_PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5765d6",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Evaluation & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "classifier.load_state_dict(torch.load(f'{OUTPUT_DIR}/best_classifier.pt'))\n",
    "classifier.eval()\n",
    "\n",
    "# Test evaluation\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        embeddings = model_fetalclip.encode_image(images)\n",
    "        embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        outputs = classifier(embeddings)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Metrics\n",
    "test_acc = np.mean(np.array(test_preds) == np.array(test_labels))\n",
    "test_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üìä TEST RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES))\n",
    "\n",
    "# Save report\n",
    "with open(f'{OUTPUT_DIR}/classification_report.txt', 'w') as f:\n",
    "    f.write(classification_report(test_labels, test_preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3996619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Confusion matrix saved to: {OUTPUT_DIR}/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04875df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "axes[1].plot(history['val_acc'], label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# F1-Score\n",
    "axes[2].plot(history['train_f1'], label='Train', linewidth=2)\n",
    "axes[2].plot(history['val_f1'], label='Validation', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('F1-Score', fontsize=12)\n",
    "axes[2].set_title('Training & Validation F1-Score', fontsize=14, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{OUTPUT_DIR}/training_curves.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Training curves saved to: {OUTPUT_DIR}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61ce573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to Drive\n",
    "import shutil\n",
    "\n",
    "print(\"\\nüíæ Copying results to Google Drive...\")\n",
    "drive_results = f'{DRIVE_DIR}/results'\n",
    "os.makedirs(drive_results, exist_ok=True)\n",
    "\n",
    "# Copy files\n",
    "shutil.copy(f'{OUTPUT_DIR}/best_classifier.pt', drive_results)\n",
    "shutil.copy(f'{OUTPUT_DIR}/classification_report.txt', drive_results)\n",
    "shutil.copy(f'{OUTPUT_DIR}/confusion_matrix.png', drive_results)\n",
    "shutil.copy(f'{OUTPUT_DIR}/training_curves.png', drive_results)\n",
    "\n",
    "print(f\"‚úÖ All results saved to: {drive_results}\")\n",
    "print(\"\\nüéâ Training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
